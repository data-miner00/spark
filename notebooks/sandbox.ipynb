{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2adcc7e9",
   "metadata": {},
   "source": [
    "# Spark Intro\n",
    "\n",
    "A very basic introduction to spark and its features.\n",
    "\n",
    "## Creating a Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aadf71e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"sandbox\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8f6022",
   "metadata": {},
   "source": [
    "## Reading Data\n",
    "\n",
    "We can use spark to read data of different types such as `csv`, `json` and `jdbc` into a Spark dataframe.\n",
    "The `inferSchema=True` tells Pyspark to read the columns with respect to their data types, otherwise Pyspark will read all of the column as string values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf700f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.option('header', 'true').csv('../data/test1.csv')\n",
    "df2 = spark.read.csv('../data/test2.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b39651a",
   "metadata": {},
   "source": [
    "## Display Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "655270c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183c6f0c",
   "metadata": {},
   "source": [
    "## Get Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3dee52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- Experience: string (nullable = true)\n",
      " |-- Salary: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956f1cee",
   "metadata": {},
   "source": [
    "## Describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62c41ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------------+-----------------+------------------+\n",
      "|summary|  Name|               age|       Experience|            Salary|\n",
      "+-------+------+------------------+-----------------+------------------+\n",
      "|  count|     6|                 6|                6|                 6|\n",
      "|   mean|  null|26.333333333333332|4.666666666666667|21333.333333333332|\n",
      "| stddev|  null| 4.179314138308661|3.559026084010437| 5354.126134736337|\n",
      "|    min|Harsha|                21|                1|             15000|\n",
      "|    max| Sunny|                31|                8|             30000|\n",
      "+-------+------+------------------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a59d682",
   "metadata": {},
   "source": [
    "## Accessing Data\n",
    "\n",
    "### Get a Column\n",
    "\n",
    "There are 2 ways to extract a column from a dataframe. The first is with the dot notation and the second is the brackets notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2fc9515",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience = df.Experience\n",
    "experience = df[\"Experience\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088e4988",
   "metadata": {},
   "source": [
    "### Get all Column Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d820b80d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name', 'age', 'Experience', 'Salary']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee45e678",
   "metadata": {},
   "source": [
    "### The Select Statement\n",
    "\n",
    "This is the Pyspark's equivalent to SQL's select statement that use to select a subset of columns from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "562f9a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "|     Name|Salary|\n",
      "+---------+------+\n",
      "|    Krish| 30000|\n",
      "|Sudhanshu| 25000|\n",
      "|    Sunny| 20000|\n",
      "|     Paul| 20000|\n",
      "|   Harsha| 15000|\n",
      "|  Shubham| 18000|\n",
      "+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select([\"Name\", \"Salary\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b934ea74",
   "metadata": {},
   "source": [
    "It can also be selected by directly passing in the name of columns without encapsulating them in an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "197d1dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "|     Name|Salary|\n",
      "+---------+------+\n",
      "|    Krish| 30000|\n",
      "|Sudhanshu| 25000|\n",
      "|    Sunny| 20000|\n",
      "|     Paul| 20000|\n",
      "|   Harsha| 15000|\n",
      "|  Shubham| 18000|\n",
      "+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"Name\", \"Salary\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8de7193",
   "metadata": {},
   "source": [
    "## Manipulating Data\n",
    "\n",
    "### Adding Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "633a790f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+------------------------+\n",
      "|     Name|age|Experience|Salary|Experience after 2 years|\n",
      "+---------+---+----------+------+------------------------+\n",
      "|    Krish| 31|        10| 30000|                    12.0|\n",
      "|Sudhanshu| 30|         8| 25000|                    10.0|\n",
      "|    Sunny| 29|         4| 20000|                     6.0|\n",
      "|     Paul| 24|         3| 20000|                     5.0|\n",
      "|   Harsha| 21|         1| 15000|                     3.0|\n",
      "|  Shubham| 23|         2| 18000|                     4.0|\n",
      "+---------+---+----------+------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('Experience after 2 years', df.Experience + 2)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da12d811",
   "metadata": {},
   "source": [
    "### Dropping a Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86cdb820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.drop('Experience after 2 years')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167ecf6e",
   "metadata": {},
   "source": [
    "### Renaming a Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7f8a422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|Age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumnRenamed('age', 'Age').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c339bf22",
   "metadata": {},
   "source": [
    "## Handling Null Values\n",
    "\n",
    "### Dropping Rows\n",
    "\n",
    "Rows with null values can be disposed with the `.na.drop()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3013f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+------+\n",
      "|     Name| age|Experience|Salary|\n",
      "+---------+----+----------+------+\n",
      "|    Krish|  31|        10| 30000|\n",
      "|Sudhanshu|  30|         8| 25000|\n",
      "|    Sunny|  29|         4| 20000|\n",
      "|     Paul|  24|         3| 20000|\n",
      "|   Harsha|  21|         1| 15000|\n",
      "|  Shubham|  23|         2| 18000|\n",
      "|   Mahesh|null|      null| 40000|\n",
      "|     null|  34|        10| 38000|\n",
      "|     null|  36|      null|  null|\n",
      "+---------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Before dropping\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9522b9",
   "metadata": {},
   "source": [
    "The `.na.drop()` is the same as `.na.drop(how=\"any\")` where `any` indicates that if a any data points of a particular row is null, the entire row will be dropped. The other value for `how` parameter is `all` and this tells Pyspark to drop the row if and only if the entire row only consists of null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dae87509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# After dropping\n",
    "df2.na.drop().show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a612ef",
   "metadata": {},
   "source": [
    "### Threshold\n",
    "\n",
    "Threshold tells Pyspark to retain the row if the number of **non-null** values in the row is at least the number of threshold specified. This will overwrite the `how` parameter.\n",
    "\n",
    "This is useful to retain meaningful records that has little amount of null values that can be imputed by appropriate values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c38cdede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "|     null| 34|        10| 38000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.na.drop(thresh=3).show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1493375",
   "metadata": {},
   "source": [
    "### Subset\n",
    "\n",
    "Subset allows the rows to be dropped if there is null value within the specified column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ed03639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "|     null| 34|        10| 38000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.na.drop(subset=[\"Experience\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20230c9c",
   "metadata": {},
   "source": [
    "### Filling Null Values\n",
    "Fill the null values for a given column with arbitrary value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01fe1aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "|   Mahesh|  0|         0| 40000|\n",
      "|     null| 34|        10| 38000|\n",
      "|     null| 36|         0|  null|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.na.fill(0, ['Experience','age']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cab906",
   "metadata": {},
   "source": [
    "### Impute Values\n",
    "\n",
    "Calculate the best value for filling a null value for a column with *median*, *mean* or *mode*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ccbc4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer = (\n",
    "    Imputer(\n",
    "        inputCols=['age', 'Experience', 'Salary'], \n",
    "        outputCols=[\"{}_imputed\".format(c) for c in ['age', 'Experience', 'Salary']]\n",
    "    )\n",
    "    .setStrategy(\"median\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b440c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+------+-----------+------------------+--------------+\n",
      "|     Name| age|Experience|Salary|age_imputed|Experience_imputed|Salary_imputed|\n",
      "+---------+----+----------+------+-----------+------------------+--------------+\n",
      "|    Krish|  31|        10| 30000|         31|                10|         30000|\n",
      "|Sudhanshu|  30|         8| 25000|         30|                 8|         25000|\n",
      "|    Sunny|  29|         4| 20000|         29|                 4|         20000|\n",
      "|     Paul|  24|         3| 20000|         24|                 3|         20000|\n",
      "|   Harsha|  21|         1| 15000|         21|                 1|         15000|\n",
      "|  Shubham|  23|         2| 18000|         23|                 2|         18000|\n",
      "|   Mahesh|null|      null| 40000|         29|                 4|         40000|\n",
      "|     null|  34|        10| 38000|         34|                10|         38000|\n",
      "|     null|  36|      null|  null|         36|                 4|         20000|\n",
      "+---------+----+----------+------+-----------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imputer.fit(df2).transform(df2).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d96fd5f",
   "metadata": {},
   "source": [
    "## Filtering\n",
    "\n",
    "Select specific rows that has the given condition met. The `.filter` clause is the same as `.where` clause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c31d6096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+\n",
      "|   Name|age|Experience|Salary|\n",
      "+-------+---+----------+------+\n",
      "|  Sunny| 29|         4| 20000|\n",
      "|   Paul| 24|         3| 20000|\n",
      "| Harsha| 21|         1| 15000|\n",
      "|Shubham| 23|         2| 18000|\n",
      "+-------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(\"Salary <= 20000\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a205c4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+\n",
      "|   Name|age|Experience|Salary|\n",
      "+-------+---+----------+------+\n",
      "|  Sunny| 29|         4| 20000|\n",
      "|   Paul| 24|         3| 20000|\n",
      "| Harsha| 21|         1| 15000|\n",
      "|Shubham| 23|         2| 18000|\n",
      "+-------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df['Salary'] <= 20000).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b15a19d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter((df['Salary'] <= 20000) | \n",
    "          (df['Salary'] >= 15000)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae26d7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(~(df['Salary'] <= 20000)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e6d1f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
